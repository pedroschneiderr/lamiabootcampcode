{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from tensorflow.keras import utils\nfrom tensorflow.keras.layers import InputLayer, Dense, BatchNormalization, Conv2D, MaxPooling2D, Flatten\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-06T18:38:50.438509Z","iopub.execute_input":"2024-09-06T18:38:50.438894Z","iopub.status.idle":"2024-09-06T18:39:05.143180Z","shell.execute_reply.started":"2024-09-06T18:38:50.438844Z","shell.execute_reply":"2024-09-06T18:39:05.142004Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"(X_train, y_train), (X_test, y_test) = mnist.load_data()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T18:40:13.228206Z","iopub.execute_input":"2024-09-06T18:40:13.228942Z","iopub.status.idle":"2024-09-06T18:40:14.998362Z","shell.execute_reply.started":"2024-09-06T18:40:13.228892Z","shell.execute_reply":"2024-09-06T18:40:14.997166Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"code","source":"X_train.shape, X_test.shape","metadata":{"execution":{"iopub.status.busy":"2024-09-06T18:40:17.671023Z","iopub.execute_input":"2024-09-06T18:40:17.671435Z","iopub.status.idle":"2024-09-06T18:40:17.680481Z","shell.execute_reply.started":"2024-09-06T18:40:17.671395Z","shell.execute_reply":"2024-09-06T18:40:17.679342Z"},"trusted":true},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"((60000, 28, 28), (10000, 28, 28))"},"metadata":{}}]},{"cell_type":"code","source":"# reshape c/ dimensão dos canais de cores para ficar de acordo com os moldes do tensorflow:\nX_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\nX_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n\n# casting de inteiro pra float para posterior normalização:\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\n# normalização (p/ [0, 1]) para tornar os cálculos da rede neural menos custosos:\nX_train /= 255\nX_test /= 255\n\n# transformação dos conjuntos de classe para codificação One Hot:\ny_train = utils.to_categorical(y_train, 10)\ny_test = utils.to_categorical(y_test, 10)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T18:40:21.036201Z","iopub.execute_input":"2024-09-06T18:40:21.036595Z","iopub.status.idle":"2024-09-06T18:40:21.144852Z","shell.execute_reply.started":"2024-09-06T18:40:21.036557Z","shell.execute_reply":"2024-09-06T18:40:21.143966Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"network = Sequential()\nnetwork.add(InputLayer(shape = (28, 28, 1)))\nnetwork.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu'))\nnetwork.add(BatchNormalization())\nnetwork.add(MaxPooling2D(pool_size = (2, 2)))\nnetwork.add(Flatten())\nnetwork.add(Dense(units = 128, activation = 'relu'))\nnetwork.add(Dense(units = 10, activation = 'softmax'))\n\nnetwork.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-09-06T18:40:27.092041Z","iopub.execute_input":"2024-09-06T18:40:27.092476Z","iopub.status.idle":"2024-09-06T18:40:27.229407Z","shell.execute_reply.started":"2024-09-06T18:40:27.092434Z","shell.execute_reply":"2024-09-06T18:40:27.228316Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"datagen_train = ImageDataGenerator(rotation_range = 7, horizontal_flip = True,\n                            shear_range = 0.2, height_shift_range = 0.07,\n                            zoom_range = 0.2)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T19:05:21.659155Z","iopub.execute_input":"2024-09-06T19:05:21.659660Z","iopub.status.idle":"2024-09-06T19:05:21.665348Z","shell.execute_reply.started":"2024-09-06T19:05:21.659615Z","shell.execute_reply":"2024-09-06T19:05:21.664152Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Na célula acima, uma instância de ImageDataGenerator é gerada. Esse objeto será um transformador, que aplicará mudanças a conjuntos de imagens de acordo com o especificado em seus parâmetros.<br>\n* rotation_range: faixa de valores, em graus, nos quais as imagens podem ser rotacionadas;\n* horizontal_flip: permite a inversão horizontal de cada imagem;\n* shear_range: proporção na qual a imagem pode sofrer o processo de \"shearing\", que é o deslocamento de linhas e colunas, mudando a forma da imagem;\n* height_shift_range: proporção com a qual a imagem pode ser deslocada para cima ou para baixo;\n* zoom_range: proporção com a qual podem ser feitos zooms nas imagens.","metadata":{}},{"cell_type":"code","source":"datagen_test = ImageDataGenerator()","metadata":{"execution":{"iopub.status.busy":"2024-09-06T19:05:35.129769Z","iopub.execute_input":"2024-09-06T19:05:35.130238Z","iopub.status.idle":"2024-09-06T19:05:35.135148Z","shell.execute_reply.started":"2024-09-06T19:05:35.130193Z","shell.execute_reply":"2024-09-06T19:05:35.133997Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"O objeto acima servirá apenas para gerar a base de teste no mesmo formato (de gerador) que a base de treinamento. Mas nenhuma transformação será aplicada, já que isso não faz sentido para base de teste.","metadata":{}},{"cell_type":"code","source":"train_ds = datagen_train.flow(X_train, y_train, batch_size = 128) # retorna um gerador que gera batches de 128 pares de treino","metadata":{"execution":{"iopub.status.busy":"2024-09-06T19:10:38.144937Z","iopub.execute_input":"2024-09-06T19:10:38.145367Z","iopub.status.idle":"2024-09-06T19:10:38.151098Z","shell.execute_reply.started":"2024-09-06T19:10:38.145328Z","shell.execute_reply":"2024-09-06T19:10:38.149864Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"test_ds = datagen_test.flow(X_test, y_test, batch_size = 128) # retorna um gerador que gera batches de 128 pares de teste","metadata":{"execution":{"iopub.status.busy":"2024-09-06T19:11:29.830124Z","iopub.execute_input":"2024-09-06T19:11:29.830538Z","iopub.status.idle":"2024-09-06T19:11:29.836164Z","shell.execute_reply.started":"2024-09-06T19:11:29.830499Z","shell.execute_reply":"2024-09-06T19:11:29.834917Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"network.fit(train_ds, epochs = 5, validation_data = test_ds)","metadata":{"execution":{"iopub.status.busy":"2024-09-06T19:14:14.975460Z","iopub.execute_input":"2024-09-06T19:14:14.975925Z","iopub.status.idle":"2024-09-06T19:17:23.261319Z","shell.execute_reply.started":"2024-09-06T19:14:14.975868Z","shell.execute_reply":"2024-09-06T19:17:23.260226Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 80ms/step - accuracy: 0.8306 - loss: 0.5171 - val_accuracy: 0.9609 - val_loss: 0.2446\nEpoch 2/5\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 78ms/step - accuracy: 0.9545 - loss: 0.1464 - val_accuracy: 0.9686 - val_loss: 0.1005\nEpoch 3/5\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 78ms/step - accuracy: 0.9628 - loss: 0.1122 - val_accuracy: 0.9654 - val_loss: 0.1101\nEpoch 4/5\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 79ms/step - accuracy: 0.9701 - loss: 0.0954 - val_accuracy: 0.9779 - val_loss: 0.0725\nEpoch 5/5\n\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 78ms/step - accuracy: 0.9741 - loss: 0.0845 - val_accuracy: 0.9733 - val_loss: 0.0904\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.history.History at 0x7d66d03f0280>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}