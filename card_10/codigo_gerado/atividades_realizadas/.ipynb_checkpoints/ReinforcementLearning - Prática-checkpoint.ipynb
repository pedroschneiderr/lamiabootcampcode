{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ae0a380-d7c3-45d1-ad8e-85ac13f753c3",
   "metadata": {},
   "source": [
    "# Objetivo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8634c40c-0d6d-405e-8eb5-601782ed1449",
   "metadata": {},
   "source": [
    "Em um jogo, treinar um taxi para levar um passageiro de um ponto a outro da maneira mais rápida possível."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bd8152-c584-47a7-bb51-5c1f5d385873",
   "metadata": {},
   "source": [
    "# Criando o ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a130293-cc20-4793-ab36-500d05786d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|R: | : :\u001b[35mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[34;1m\u001b[43mY\u001b[0m\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym #biblioteca com funções e ambientes para treinamento por reforço\n",
    "import random\n",
    "\n",
    "random.seed(1234) #padronizar os valores aleatórios entre runtimes diferentes\n",
    "\n",
    "streets = gym.make(\"Taxi-v3\").env #cria o ambiente com o taxi, pontos e ruas\n",
    "streets.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c9f226-5296-4b63-a39b-2f87626efc11",
   "metadata": {},
   "source": [
    "Resumo do significado de cada parte:\n",
    "1. As letras são pontos de destino e busca de passageiro.\n",
    "2. A letra azul é onde o táxi deve buscar o passageiro.\n",
    "3. A letra roxa é para onde o táxi deve levar o passageiro.\n",
    "4. As linhas | representam paredes pelas quais o táxi não consegue passar.\n",
    "5. O retângulo preenchido é o táxi, que está amarelo quando vazio, e verde quando tem passageiro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794abea4-f007-4370-afd4-d08984b57a61",
   "metadata": {},
   "source": [
    "O ambiente é 5x5 (25 localizações possíveis)\n",
    "O que define um estado do ambiente:\n",
    "1. Onde o táxi está (25 possibilidades).\n",
    "2. Onde o atual destino é (4 possibilidades).\n",
    "3. Onde o passageiro está (5 possibilidades, nas letras e dentro do táxi)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f80a3-d0b3-4b9f-a6dd-9c5ab03b56c3",
   "metadata": {},
   "source": [
    "Ou seja, há 25 x 4 x 5 = 500 estados possíveis nesse ambiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47aa16a2-a564-4e4c-a3ff-5ca592c8a8aa",
   "metadata": {},
   "source": [
    "Para cada estado, há 6 possíveis ações:\n",
    "1. O táxi se mover para leste, oeste, norte ou sul.\n",
    "2. Pegar um passageiro.\n",
    "3. Largar um passageiro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60507b01-8b6a-4d4e-a540-cc43b16852c8",
   "metadata": {},
   "source": [
    "Os valores Q serão dados pelos seguintes critérios:\n",
    "1. Largar o passageiro no local correto dá +20 pontos ao atual par (estado, ação).\n",
    "2. Todo (estado, ação) enquanto carregando um passagerio resulta em -1 ponto pro (estado, ação). Isso incentiva o encurtamento dos caminhos.\n",
    "3. Pegar ou largar um passageiro no lugar errado dá uma penalidade de -10 pontos para o (estado,ação)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f19c76-4d20-4c7e-aef6-0bf4993348e1",
   "metadata": {},
   "source": [
    "Vamos começar colocando o táxi na localização (2, 3), com o passageiro na localização de busca 2, e o destino na localização 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d88ab8c-61ce-42f5-a62a-458aada0ed77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|\u001b[35mR\u001b[0m: | : :G|\n",
      "| : | : : |\n",
      "| : : :\u001b[43m \u001b[0m: |\n",
      "| | : | : |\n",
      "|\u001b[34;1mY\u001b[0m| : |B: |\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "initial_state = streets.encode(2, 3, 2, 0) #forma um objeto de estado com esses parâmetros\n",
    "streets.s = initial_state #assinala o estado atual do ambiente streets para esse\n",
    "streets.render() #imprime o ambiente em seu estado atual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6edcaaca-f8de-41a1-b2d0-657d61a9f0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: [(1.0, 368, -1, False)],\n",
       " 1: [(1.0, 168, -1, False)],\n",
       " 2: [(1.0, 288, -1, False)],\n",
       " 3: [(1.0, 248, -1, False)],\n",
       " 4: [(1.0, 268, -10, False)],\n",
       " 5: [(1.0, 268, -10, False)]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streets.P[initial_state]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11646950-1f5d-4dec-8ddf-735ef32728f2",
   "metadata": {},
   "source": [
    "Essa é o dicionário de recompensa para cada 1 das 6 ações possíveis nesse estado(ir a sul, leste, oeste, norte, largar o passageiro, pegar o passageiro), e cada uma tem associada a ela uma tupla com valores que indicam: a probabilidade de se tomar aquela ação, o estado em que o ambiente ficaria após ela (dos 500 possíveis), o valor Q adicionado ao par (estado, ação) e se essa ação resultaria no cumprimento da missão (largar o passageiro na letra roxa)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767c6646-85ad-4442-aa68-714f85496648",
   "metadata": {},
   "source": [
    "Agora vamos programar a Q-Learning, com 10000 simulações de corridas do táxi, avançando um passo no tempo em cada corrida, com 10% de chance do taxi tomar uma decisão aleatória/exploratória ao invés de escolher a com maior valor Q:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85f92a1d-72cc-4b5b-bf04-2f1654854828",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "q_table = np.zeros([streets.observation_space.n, streets.action_space.n]) #array numpy que contém todas as combinações de estados e ações no ambiente, com seus valores inicializados para 0\n",
    "\n",
    "learning_rate = 0.1 \n",
    "discount_factor = 0.6 #fator de \"trigger-back\" do valor de uma ação para as anteriores\n",
    "exploration = 0.1 #chance de se tomar uma ação aleatória não baseada nos valores Q\n",
    "epochs = 10000 #número de corridas\n",
    "\n",
    "for taxi_run in range(epochs):\n",
    "    state = streets.reset() #reseta o ambiente para uma nova corrida\n",
    "    done = False\n",
    "    \n",
    "    while not done:\n",
    "        random_value = random.uniform(0, 1) #gera um float aleatória entre 0 e 1\n",
    "        if (random_value < exploration):\n",
    "            action = streets.action_space.sample() #explora uma ação aleatória\n",
    "        else:\n",
    "            action = np.argmax(q_table[state]) #toma a ação com o maior valor Q\n",
    "            \n",
    "        next_state, reward, done, info = streets.step(action) #aplica a ação e retorna os resultados\n",
    "        \n",
    "        prev_q = q_table[state, action]\n",
    "        next_max_q = np.max(q_table[next_state])\n",
    "        new_q = (1 - learning_rate) * prev_q + learning_rate * (reward + discount_factor * next_max_q) #equação da Q-Learning, de \"trigger-back\"\n",
    "        q_table[state, action] = new_q #atualiza a tabela de valores Q para esse par de estado e ação\n",
    "        \n",
    "        state = next_state #passa para o próximo estado, resultando da última ação\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e1a084f-71b2-40ea-986c-bb4e6b572c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.42376178, -2.41530761, -2.39404973, -2.3639511 , -9.0034776 ,\n",
       "       -8.06209957])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table[initial_state]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f072f30d-0408-4b2f-b6a9-53767e797e0d",
   "metadata": {},
   "source": [
    "Esses são os valores associados a cada ação possível no estado inicial baseados nos valores aprendidos no bloco anterior, pela Q-Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd771d36-3e35-4dbc-a137-7c069167cf2d",
   "metadata": {},
   "source": [
    "## Testando os valores Q encontrados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6446e3df-daf4-405d-8f1a-97737d78eaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trip number 10 Step 24\n",
      "+---------+\n",
      "|R: | : :\u001b[43mG\u001b[0m|\n",
      "| : | : : |\n",
      "| : : : : |\n",
      "| | : | : |\n",
      "|\u001b[35mY\u001b[0m| : |\u001b[34;1mB\u001b[0m: |\n",
      "+---------+\n",
      "  (North)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from time import sleep\n",
    "\n",
    "for tripnum in range(1, 11): #teste com 10 corridas\n",
    "    state = streets.reset() #reseta o ambiente para uma nova corrida\n",
    "   \n",
    "    done = False\n",
    "    trip_length = 0\n",
    "    \n",
    "    while not done and trip_length < 25: #limita a corrida a 25 passos ou a quando o passageiro é largado no ponto correto\n",
    "        action = np.argmax(q_table[state]) #toma a decisão de maior valor Q\n",
    "        next_state, reward, done, info = streets.step(action) #toma a ação e captura os dados das consequências\n",
    "        clear_output(wait=True)\n",
    "        print(\"Trip number \" + str(tripnum) + \" Step \" + str(trip_length))\n",
    "        print(streets.render(mode='ansi'))\n",
    "        sleep(.5)\n",
    "        state = next_state #passa para o próximo estado, consequência da última ação\n",
    "        trip_length += 1\n",
    "        \n",
    "    sleep(2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b915faf-83c1-435f-a28f-4f6eef0120ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
